
scenario: "eot/turret_2v1_updated"

env_args:
    ###########################################
    #               Environment               #
    ###########################################
    done_callback: True           # Whether the scenario uses a done callback for terminal check
    done_all: True                # Flag for specifying whether to check done for all agents. If not set it will check if any agent is done.
    logging_callback: True        # Whether the scenario has a logging callback for environment information
    num_obstacles: 0              # number of obstacles
    num_adversaries: 2            # Number of adversary agents
    num_fixed_adv: 0              # Number of adversaries using a fixed strategy

    remove_obstacles_feat: True
    observe_state: False          # whether an observation is only partial (False) or central including agent position (True)
    observe_grid_pos: True        # observe agent ID, instead of agent presence (only for state_as_list=False)
    observe_ids: True             # observe agent ID, instead of agent presence (only for state_as_list=False)
    observe_one_hot: False        # observe agent ID as one-hot vector (only for observer_ids=True)
    state_as_graph: False         # whether the state is a list of entities (True) or the entire grid (False
    world_shape: [ 51, 51 ]       # the shape of the grid-world [height, width]

    ###########################################
    #                 Reward                  #
    ###########################################
    dense_reward: False        # Flag for whether to use dense reward for training
    reward_turret_hit: 20      # reward for the turret hitting an agent
    reward_turret_touch: 10    # penalty for the turret being touched by an agent
    reward_agent_touch: 20     # reward for the agent touching the turret
    reward_agent_hit: 10       # penalty for the agent being hit by the turret
    reward_collision: 0        # reward (or punishment) for colliding with other agents
    reward_time: 0.0           # reward (or punishment) given at each time step
    reward_scale: 1.0          # Value by which to scale the reward

    ###########################################
    #                  Agent                  #
    ###########################################
    turret_scenario: True           # Flag for whether to use turret scenario environment behaviour
    fixed_turret: True              # Flag specifying whether the scenario uses a fixed turret agent
    all_touch: True                 # All attackers must be hit or touch turret for terminal state
    goal_radius: 0.25               # Radius attackers are trying to get inside
    nu: 0.075                       # Attacker v divided by Turret ang v
    visibility_from_goal: 0.3       # How far outside the goal radius turret can see
    spawn_outside_sense: False      # Attackers should spawn outside of turret sense region
    spawn_optimal: False            # Spawn attackers 180 degrees away from each other. Makes spawn-outside nugatory

    ###########################################
    #             Adjacency Matrix            #
    ###########################################
    cg_topology: 'full'
    use_torch: True
    use_tf: False
    use_self_attention: True
    proximal_distance: 2.0

    ###########################################
    #                  Debug                  #
    ###########################################
